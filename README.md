# ğŸ§  Energy-Based GAN (EBGAN) on CIFAR-10  
*By Achraf Guenounou*

## ğŸ“˜ Overview

This project implements an **Energy-Based Generative Adversarial Network (EBGAN)** to generate realistic images from the CIFAR-10 dataset. Unlike traditional GANs, EBGAN uses an **autoencoder-based discriminator** that assigns an energy score to each sample based on reconstruction error, promoting a more stable training process.

---

## ğŸ” What is EBGAN?

EBGAN is a GAN variant where:
- The **generator** produces fake images aiming to minimize their energy score.
- The **discriminator** is an **autoencoder** that reconstructs real/fake images and assigns an energy value based on reconstruction quality.

### âœ³ï¸ Pulling-away Term (PT)
A regularization technique that avoids mode collapse by penalizing similar feature vectors in the generated batch using cosine similarity.

---

## ğŸ§± Model Architecture

### ğŸ”· Generator
- Dense â†’ Reshape to (8Ã—8Ã—128)
- Conv2DTranspose â†’ (16Ã—16Ã—128) â†’ BatchNorm + ReLU
- Conv2DTranspose â†’ (32Ã—32Ã—64) â†’ BatchNorm + ReLU
- Conv2DTranspose â†’ (32Ã—32Ã—3) â†’ Tanh

### ğŸ”· Discriminator
- Image input + Class input â†’ Concatenated
- Conv2D â†’ (16Ã—16Ã—128) â†’ LeakyReLU
- Conv2D â†’ (8Ã—8Ã—128) â†’ BatchNorm + LeakyReLU
- Conv2D â†’ (4Ã—4Ã—64) â†’ BatchNorm + LeakyReLU
- Flatten â†’ Dense(64) â†’ Dense(1)

---

## ğŸ§ª Training Data

**Dataset**: CIFAR-10  
- 60,000 color images (32Ã—32 pixels, 10 classes)  
- **Training set**: 50,000 images  
- **Testing set**: 10,000 images  
- **Preprocessing**: Normalization to [-1, 1] and reshaping

---

## âš™ï¸ Model Parameters

| **Parameter**            | **Value**                 |
|--------------------------|--------------------------|
| Optimization Algorithm   | Adam                     |
| Learning Rate            | 0.0001                   |
| Beta_1                   | 0.5                      |
| Epochs                   | 200                      |
| Batch Size               | 256                      |
| Noise Vector Size        | 100                      |
| Discriminator Loss       | Energy-Based Loss        |
| Generator Loss           | Minimize Energy Score    |

---

## ğŸ“ˆ Performance

- **EBGAN** with normalized energy loss produced more stable and visually realistic outputs than baseline CGAN using binary cross-entropy.
- Demonstrated **more stable training curves**.
- Generated images improved across epochs.

---

## ğŸ–¼ï¸ Sample Outputs

Images were generated at regular intervals during training.  
Results show **higher visual quality with normalization** and the use of the **energy function**.

---

## âœ… Summary

- Minimizes energy scores of generated samples  
- More stable training than traditional GANs  
- Suited for semi-supervised learning  

---

## ğŸ”§ Future Improvements

- Implement a fully functional autoencoder structure  
- Test with more complex datasets (e.g., CelebA, STL-10)  
- Apply to new domains like **anomaly detection** or **network intrusion detection**  

---

## ğŸ“š References

- [Energy-Based GANs (Zhao et al., 2016)](https://arxiv.org/pdf/1609.03126)  
- [Sik-Ho Tsangâ€™s Review on EBGAN](https://sh-tsang.medium.com/review-ebgan-energy-based-generative-adversarial-network-gan-9dcc4bba9d7b)

---

## ğŸ™‹â€â™‚ï¸ Author

**Achraf Guenounou**  
Neural Network Lab â€” February 2025
